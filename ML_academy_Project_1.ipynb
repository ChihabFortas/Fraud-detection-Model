{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML academy Project_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9mcCv/wOWscJNDjo7nmbA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChihabFortas/Fraud-detection-Model/blob/main/ML_academy_Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Fraud Detection using regression model**\n",
        "####**Project overview**\n",
        "The Tunisian company of electricity and gaz (STEG) is a non-administrative company, it is responsible for delivering electricity and gaz across Tunisia.\n",
        "The company sufferred tremendous losses in order of 200 million tunisian dinars due to fraudelant manipulations of meters by consumers.\n",
        "\n",
        "in this project we will be using data gathered by the company (Clients billing/consumption history) to detect and recognize clients involved in fraudelent activities. "
      ],
      "metadata": {
        "id": "fj-J5trrMTSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Project structure** \n",
        "before start writing any code, first we need to understand the problem in details and set a some milestones to achieve in this project.\n",
        "\n",
        "- Exploratory Data Analysis\n",
        "  - downloading the data and converting it into a readable dataset\n",
        "  - understanding the data \n",
        "  - Data preparation and cleaning\n",
        "  - Deciding the features to build the model\n",
        "\n",
        "- Model creation\n",
        "  - Decide which type of Model fit to solve the problem in hand\n",
        "  - Create the model based on input and output shape and the depth of model network\n",
        "  - Create the model hyperparamater\n",
        "  - create the training job \n",
        "\n",
        "- Visualizing and tuning\n",
        "  - continue visualizing and tuning the hyperparamaters until we reach a optimized state\n",
        "  - Model validation and testing"
      ],
      "metadata": {
        "id": "VVH4-IPgOOlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Python 2 / 3 compatability\n",
        "from __future__ import print_function"
      ],
      "metadata": {
        "id": "okxfLiHCRhS6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz14LGv-Lpa8",
        "outputId": "75057cf8-ff53-49b2-cab0-4a7e5a094c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported modules.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "print(\"Imported modules.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the dataset\n",
        "we will be using the dataset provided to us by the ML academy via google drive. The following code cell download the data from google drive, loads it and then creates the following two pandas DataFrames:\n",
        "\n",
        "*   train_df, which contains the training set\n",
        "\n",
        "*   test_df, which contains the test set"
      ],
      "metadata": {
        "id": "6CzM0T4mRvAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOQAhb0-T3PS",
        "outputId": "f4f2c921-b1ff-483d-c687-0b2482d32c1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Shared Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/drive/My\\ Drive/foo.txt"
      ],
      "metadata": {
        "id": "0dt8JvfaT7xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://drive.google.com/file/d/1Unhg1OagxzEmaiCvgqLbRumIoDjx4AcV/view?usp=sharing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9z7C953UiZc",
        "outputId": "a888097b-ac86-418f-c131-d4bfb7edd8c1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-25 13:01:19--  https://drive.google.com/file/d/1Unhg1OagxzEmaiCvgqLbRumIoDjx4AcV/view?usp=sharing\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.142.138, 74.125.142.100, 74.125.142.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.142.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘view?usp=sharing.1’\n",
            "\n",
            "view?usp=sharing.1      [ <=>                ]  62.15K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-01-25 13:01:20 (2.04 MB/s) - ‘view?usp=sharing.1’ saved [63641]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XrB_9A65Uieu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "train_df = train_df.reindex(np.random.permutation(train_df.index)) # shuffle the examples\n",
        "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")"
      ],
      "metadata": {
        "id": "f5ee8KzTRsqK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}